---
title: "main.java.spamizer"
author: "Marc S√†nchez, Francesc Xavier Bullich, Gil Gass√≥"
date: "5/8/2019"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

// TODO : Posar el projecte al github.



\newpage




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Carreguem les llibreries
library(scatterplot3d)
library(ggplot2)
library(colorspace)
library("plot3D")

# Carreguem les dades per a l'execuci√≥ del gr√†fic.
#resultsP1723K005 = read.csv("/home/marc/projects/main.java.spamizer/analisys/2000m-1000n-phi-1.7-2.3-k-0-0.5.csv")
```


```{r Functions}

# x √©s el nom del fitxer que volem carregar
loadFormattedData <- function(x){
  
  tmp = read.csv(x)
  names(tmp) <- c("id", "phi", "k", "tp", "tn", "fp", "fn", "nham", "nspam")
  
  #Calculem els tcr dels valors 
  # BASE :  (NSPAM) / (50 * NHAM + NSPAM) 
  base <- tmp$nspam / (50 * tmp$nham + tmp$nspam)
  # WERR: (50 * FP + FN)/(50 * NHAM + NSPAM) + 0.000001 -> per que no sigui 0
  werr <- (50 * tmp$fp + tmp$fn) / (50 * tmp$nham + tmp$nspam) + 0.000001
  # TCR : BASE / WERR
  tcr <- base/werr
  
  # Calculem l'accuracy
  accuracy <- (tmp$nspam + tmp$nham - tmp$fp - tmp$fn)/(tmp$nspam + tmp$nham) * 100
  
  # Generar una matriu que permeti representar els resultats en funci√≥ de k i phi
  values <- data.frame(accuracy, tcr)
  names(values) <- c("accuracy", "tcr")
  head(values)
  
  tmp <- cbind(tmp, values)
  
  # Ordenem els valors
  tmp <- tmp[order(-tmp$tcr), ]

   return(tmp)
}

```





# Naive Bayes

En aquest apartat s'especifica com s'adapta el m√®tode de naive bayes al filtratge de correu. 

## Naive Bayes. 

// TODO : S'ha de parlar de tot el que es fa a dins del m√®tode que tenim implementat al codi. 

DescripciÛ del codi amb el qual implementem el mËtode Naive Bayes.

Codi implementat:

```{r eval=FALSE}

 public boolean isSpam(MemDB memDB, Collection<String> message, double k, double phi)  {
        double spamProbability=0;
        double hamProbability=0;

        int hamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.HAM);
        int spamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.SPAM);

        List<String> words = new ArrayList<>(message);
        hamProbability = memDB.calculateProbability(words, TableEnumeration.Table.HAM,k,hamAlphabet);
        spamProbability = memDB.calculateProbability(words, TableEnumeration.Table.SPAM,k,spamAlphabet);

        double pTotalSpam = memDB.getMessageProbabylity(MemDB.Column.SPAM,k);
        double pTotalHam = memDB.getMessageProbabylity(MemDB.Column.HAM,k);

        //Tenim la probatilitat sumada de cada una de les paraules del missatge en forma de logaritme
        //sumem les probatilitats de que els missatges siguin spam o ham en forma de logaritme
        hamProbability += pTotalHam;
        spamProbability += pTotalSpam;

        //comparem les probabilitats obtingudes aplicant el parametre phi.
        return (spamProbability) > ((hamProbability)+ Math.log(phi));


    }
```

DescripciÛ pas a pas de les variables i funcions implementades.

Primer de tot el que fem Ès declarar dues variables que ens servir‡n per guardar tan la probabilitat total de que un missatge sigui spam o que sigui ham.

```{r eval=FALSE}
  double spamProbability=0;
  double hamProbability=0;
```

AquÌ el que fem Ès declarar dos enters que ens guarden el total de paraules que tenim registrades en la base de dades en memÚria com a spam i com a ham.

```{r eval=FALSE}
  int hamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.HAM);
  int spamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.SPAM);
```

Assignem els valors a les probabilitats de Ham i Spam. Sumem la probabilitat de cadascuna de les paraules del missatge de que siguin ham o spam.

```{r eval=FALSE}
  List<String> words = new ArrayList<>(message);
  hamProbability = memDB.calculateProbability(words, TableEnumeration.Table.HAM,k,hamAlphabet);
  spamProbability = memDB.calculateProbability(words, TableEnumeration.Table.SPAM,k,spamAlphabet);
```

Declarem dos variables que contindran els valors de la probabilitat total de que un missatge sigui spam o sigui ham.

```{r eval=FALSE}
  double pTotalSpam = memDB.getMessageProbabylity(MemDB.Column.SPAM,k);
  double pTotalHam = memDB.getMessageProbabylity(MemDB.Column.HAM,k);
```

Aquestes tan la suma de probabilitats de cada paraula del missatge com la probabilitat del missatge de ser spam o ham, est‡n logarimitzades, i per tant el que fem al final Ès sumar aquestes dades.

```{r eval=FALSE}
//Tenim la probatilitat sumada de cada una de les paraules del missatge en forma de logaritme
//sumem les probatilitats de que els missatges siguin spam o ham en forma de logaritme
  hamProbability += pTotalHam;
  spamProbability += pTotalSpam;
```

Finalment apliquem la fÛrmula amb phi quen ens permet donar import‡ncia al fet de  no classificar missatges Ham com a Spam, per tant com que volem estar segurs d'aixÚ fem el seg¸ent:
mirem que per classificar un missatge com a Spam, la probabilitat de ser spam ha de ser mÈs gran que phi vegades la probabilitat de que sigui ham.

```{r eval=FALSE}
(spamProbability) > ((hamProbability)+ Math.log(phi));
```



## Assumpcions.

El m√®tode de Naive Bayes assumeix que les caracter√≠stiques dels elements que analitza s√≥n independents entre si.

En el cas de processament de textos assumeix que cada una de les paraules d'un mateix bloc s√≥n independents de la resta.
Aix√≤ √≤bviament no √©s cert. Les frases es construeixen a partir d'una gram√†tica i tenen una sem√†ntica que relaciona cada una de les paraules que cont√© amb les altres. Per tant el fet de trobar X paraula al costat de Y √©s degut a una depend√®ncia entre elles.

Si consider√©ssim les depend√®ncies entre els elements, segurament nom√©s podr√≠em classificar exemples id√®ntics als que ja tenim classificats, per tant seria totalment in√∫til.

D'altra banda si considerem que les caracter√≠stiques s√≥n independents fa que puguem comptabilitzar m√©s cops elements que de forma conjunta (depenent) nom√©s comptabilitzar√≠em 1 sol cop.

En l'exemple dels correus:

- Si tenim en compte que les paraules d'una frase s√≥n depenents, trobar 1 frase que nom√©s surti a ham ens incrementa la probabilitat que el missatge sigui ham
- Si pel contrari assumim la independ√®ncia entre paraules. Comptabilitzarem cada una de les paraules de la frase, incrementant la probabilitat que sigui ham (aqu√≠ es pot veure la ingenu√Øtat del m√®tode).

## Punts forts i febles del m√®tode de Naive Bayes.

Punts forts:

- L'algoritme √©s prou f√†cil de construir i d'entendre.
- √âs un algoritme prou r√†pid i d√≥na prou bons resultats.
- Es pot entrenar amb un conjunt relativament petit d'exemples.
- En els casos que es compleixi l'assumpci√≥ d'independ√®ncia el m√®tode funciona millor.

Punts febles:

- L'assumpci√≥ d'independ√®ncia dels exemples pot fer que la classificaci√≥ no sigui correcte si no t√© una bona base d'exemples (ben diferenciats)
- El conjunt d'exemples ben diferenciat √©s dif√≠cil de trobar fora del m√≥n acad√®mic.
- Les caracter√≠stiques que no surtin al conjunt d'entrenament no es poden classificar correctament, ja que la probabilitat que assigna el m√®tode √©s 0.
- Si s'entrena malament la m√†quina, la m√†quina acaba enganyant. 
- Si hi ha molta difer√®ncia en nombre d'elements entre els diferents bag of words podem trobar inconsist√®ncies en els resultats.


# Applicaci√≥.

// TODO: 

## Tecnologies escollides.

L'aplicaci√≥ est√† feta en java en un format de comanda c. Per veure com s'executa l'aplicaci√≥ es pot consultar l'apartat manual de l'aplicaci√≥. La idea √©s generar un paquet jar i que rebi par√†metres.

S'han aplicat patrons de disseny de software tals com el patr√≥ strategy i el patr√≥ singleton. El patr√≥ strategy s'aplica en general a totes les possibles operacions que poden ser canviades en temps d'execuci√≥ mentre que el patr√≥ singleton s'aplica als accessos a les bases de dades.

L'aplicaci√≥ cont√© 2 bases de dades on es desa la informaci√≥ relativa al filtre. Una base de dades en mem√≤ria i una base de dades desada en local en un o diversos fitxers.

A causa del nombre de dades que es processen a casa execuci√≥ s'han replantejat les tecnologies escollides.

### Versi√≥ 1 

La primera versi√≥ de l'aplicaci√≥ i despr√©s de consultar diferents projectes relacionats amb el machine learning es va plantejar mitjan√ßant bases de dades SQL, concretament una base de dades feta amb HSQLDB en mem√≤ria i una base de dades tamb√© HSQLSB desada en un fitxer.

### Versi√≥ 2

Per culpa de la gran quantitat de dades que s'havia de processar i localitzant un coll d'ampolla en les operacions de logarimitzar que s'havien de fer sobre les dades extretes dins de les mateixes sent√®ncies SQL, s'ha implementat una segona versi√≥ mitjan√ßant hashsets i mitjan√ßant fitxers .csv (Comma separated values).

## Manual de l'aplicaci√≥.

La versi√≥ 2 corregeix la lentitud de l'acc√©s a les dades. Utilitza un mapa clau valor per les aparicions de les paraules de ham i un mapa clau valor per les aparicions de les paraules d'spam. Aix√≠ mateix els valors del total de missatges de ham i spam s√≥n comptadors i l'alphabet es representa amb un Set, √©s a dir, amb un conjunt de paraules.

```{r app_manual}
# usage: main.java.spamizer
#  -c <arg>   Usage : -c <spamDir> <hamDir> [-n <int>]
#             Receives 2 parameters, A directory with spam mails and a
#             directory with ham mails. A calculation for values phi and k
#             will be done using a selection for the mails set. By default
#             the selection will be random based on k-fold cross-validation
#             and the heuristic method used to calculate phi and k values
#             will be random
#  -d         Flag that indicates that data must be loaded from local
#             database, this database is allocated inside project dir named
#             db made by csv files
#  -h         Set training mails as ham, adding this argument -s must not be
#             present
#  -n <arg>   The number of iterations for -c mode execution.
#  -p         Set the persistance of the memory database to a local database
#  -s         Set training mails as spam, adding this argument -h must not
#             be present
#  -t <arg>   Directories where training mails in txt are stored, this or
#             database argument must be present you can set a maximum of 2
#             directories in this several order : -t <spamDir> <hamDir>. If
#             only one dir is set the parameter -h or -s must be included
#  -v <arg>   Directory where validation mails in txt are stored. This
#             procedure will validate mail inside validationDir with
#             database loaded by default or stored inside memory. [-h | -s]
#             -v <validationDir> .
            
```

## Utilitzaci√≥.

// TODO : Com utilitzar el jar i exemples d'execuci√≥. 


# Implementaci√≥

En aquest apartat s'expliquen els blocs amb qu√® s'ha dividit la part d'enginyeria del software aplicada a aquesta pr√†ctica, en concret els seg√ºents apartats mostren els patrons strategy.

## Lectura de fitxers. 

La interf√≠cie reader proporciona l'obligaci√≥ d'implementar el m√®tode que permet llegir i extreure textos d'una font de dades.

De la mateixa manera s'ha generat el DirectoryMailReader que implementa la interf√≠cie Reader i que √©s la classe que gestiona l'acc√©s a un directori en concret per extreure'n un llistat de correus.

## M√®tode de selecci√≥.

La interf√≠cie Selector √©s la que s'utilitza per separar el conjunt d'entrenament i de validaci√≥. Al ser una interf√≠cie, permet canviar el m√®tode de selecci√≥ en temps d'execuci√≥ i fent f√†cil la incorporaci√≥ de nous m√®todes de selecci√≥.

Aquest m√®tode entraria nom√©s a l'apartat -c de les execucions. Donades dues col¬∑leccions de correus √©s capa√ß d'extreure un subconjunt per spam i un subconjunt per ham deixant un tercer subconjunt com a correus per validar. S√≥n objectes correu i per tant, com a objecte correu, ja s'incorpora un camp boole√† que estipula si el correu √©s spam o ham. Aquest boole√†  s'utilitza al final de la validaci√≥ per comptabilitzar el nombre de correus classificats com a tp, fp, tn i fn.

### Adaptaci√≥ del m√®tode K-fold cross-validation.

El m√®tode k-fold cross-validation aplica una divisi√≥ del total d'objectes de la poblaci√≥ en n parts. Donada aquesta divisi√≥ el mateix m√®tode va rotant, entrenant la BD amb n-1 parts i posteriorment aplica el m√®tode de validaci√≥ per la part que no s'ha fet servir per entrenar.

En el nostre cas tot i anomenar-lo k-fold cross-validation, **sabem que no ho √©s**, l'anomenem aix√≠ per qu√® ens vam basar en ell per definir el nostre m√®tode de selecci√≥.

Aquest consisteix en discriminar de la lectura un percentatge de correus (en el nostre cas entre el 5% i el 15% generat aleat√≤riament) del total de cada directori i posar-lo en una altra col¬∑lecci√≥ anomenada unknown. Aquesta col¬∑lecci√≥ ser√† utilitzada per a la validaci√≥ mentre que la resta s'utilitzen per training. Val a dir que la selecci√≥ es fa mitjan√ßant la generaci√≥ d'un nombre aleatori. Si el nombre √©s inferior al % generat el classifiquem com a unknown, en canvi si √©s superior o igual el classifiquem com spam o ham en funci√≥ del directori que s'estigui processant.

### Fixed Selection

La selecci√≥ fixada ha sigut implementada per a poder calcular m√©s acotadament els valors de phi i k. La selecci√≥ fixada sempre processa els mateixos correus amb el mateix ordre i discrimina els mateixos. D'aquesta manera podem generar execucions id√®ntiques amb valors diferents de les constants phi i k. Ens √©s molt √∫til per estudiar el seu comportament.

## Filtre i abstracci√≥ del filtratge.

La interf√≠cie Filter permet generalitzar el filtratge de text procedent de cada correu electr√≤nic. Fent que es pugui canviar de filtre en temps d'execuci√≥. Tamb√© millora l'escalabilitat permetent que se'n puguin afegir de nous nom√©s implementant aquesta interf√≠cie.

### Stanford Core NLP.

La gent de Stanford ens proporciona una gran llibreria per al processament de textos. Veure la refer√®ncia [2]. La llibreria s'anomena Stanford Core NLP lib. Dins d'ella s'implementa un m√®tode de "tokenitzaci√≥", √©s a dir generaci√≥ de tokens per paraules que permeten estructurar el text i realitzar diferents comprovacions, com ara:

- Saber la categoria gramatical de la paraula (Nom, verb, determinant...)
- Posicionament de les paraules dins de par√†grafs, frases, expressions...
- Permet la **Lematitzaci√≥ de les paraules**, √©s a dir cercar l'arrel d'aquestes.
- An√†lisi de sentiments de les expressions dient si una frase √©s positiva, negativa ...
- Extreure subjecte, verb i predicats...

Entre altres.

Ens hauria agradat explotar m√©s aquesta llibreria per√≤ el temps per a la realitzaci√≥ de la pr√†ctica i el seu mateix objectiu ens allunyava de la possibilitat d'estudiar-la m√©s a fons, concretament el nostre filtre basat en StanfordCoreNLP realitza una discriminaci√≥ de totes les paraules que no s√≥n noms, verbs, adjectius, adverbis i lematitza tot el que li passen.

M√©s endavant hi ha conclusions sobre l'√∫s de la mateixa llibreria.

### Custom Filter.

Aquest filtre simplement deixa passar tot el que se li d√≥na sempre que cada paraula compleixi amb el seu invariant sem√†ntic, √©s a dir, que tingui algun car√†cter. Extreu tamb√© les paraules "Subject:", "cc", "from" i "to", que tot i que en els correus de prova no hi s√≥n, en altres paquets de correus s√≠ que pot ser que ens els trobem. Tamb√© filtra els "\n" i "\r". 

## Entrenament. 



## Validaci√≥.

// TODO : Explicar la nostre adaptaci√≥ del m√®tode hill climbing utilitzat. 

## Compute (main.java.Application, adaptaci√≥ del m√®tode Hill Climbing).























# Fase Experimental.

En aquesta fase es presenten una s√®rie de gr√†fics i una an√†lisi (no confirmat) sobre totes les execucions que s'han anat realitzant.

## C√†lcul del TCR (Total Cost Ratio)

Amb el Total cost ratio podem extreure un valor que pondera amb m√©s for√ßa el valor de les aparicions dels falsos positius. El que es busca amb el TCR √©s el valor m√†xim possible. Per fer-ho hem realitzat diverses execucions i hem preparat una s√®rie de conclusions per intentar esbrinar les funcions phi i k que millor s'ajusten al nostre problema mitjan√ßant el c√†lcul del TCR.

### Veiem com es pot generar la columna TCR

```{r tcr}
results = read.csv("./20000m-500n-SF.csv")
#Calculem els tcr dels valors 
# BASE :  (NSPAM) / (50 * NHAM + NSPAM) 
base <- results$NSPAM / (50 * results$NHAM + results$NSPAM)
# WERR: (50 * FP + FN)/(50 * NHAM + NSPAM) + 0.000001 -> per que no sigui 0
werr <- (50 * results$FP + results$FN) / (50 * results$NHAM + results$NSPAM) + 0.000001
# TCR : BASE / WERR
tcr <- base/werr

# Generar una matriu que permeti representar els resultats en funci√≥ de k i phi
values <- data.frame(results$PHI, results$K, tcr)
names(values) <- c("phi", "k", "tcr")
head(values)

# Ordenem els valors
values <- values[order(-values$tcr), ]
head(values,20)

```

## An√†lisi de la PHI i la K.

Carreguem les diferents simulacions en un dataframe per poder processar les dades. Utilitzem la funci√≥ loadFormattedData declarada a l'apartat de funcions del document. Aquesta funci√≥ ens afegeix les columnes calculades per l'accuracy i el TCR.

```{r Loading data}
b1 = loadFormattedData("./m20000-n9500-SF-P-16-k-03.csv")
b2 = loadFormattedData("./m20000-n10000-P-15-K-03.csv")
b3 = loadFormattedData("./20000m-500n-SF.csv")
b4 = loadFormattedData("./2000m-1000n-phi-1.7-2.3-k-0-0.5.csv")

v <- rbind(b1, b2, b3, b4)
v <- v[order(-v$tcr), ]
head(v)
```

### PHI

Analitzant el qu√® representen els valors de phi, el que ens trobem √©s que la phi √©s el factor d'increment de la probabilitat que un correu sigui considerat SPAM. √âs a dir un valor de phi = 2, provoca que un correu nom√©s ser√† considerat spam si la seva probabilitat √©s 2 cops superior a la probabilitat de ser ham. Un valor de phi = 1 fa que no hi hagi increment obligatori per a la comparaci√≥.

El valor m√≠nim que t√© sentit assignar-li a phi √©s 1 i el m√†xim el podr√≠em limitar a 5 com a molt o incl√∫s a 6 si el que volem √©s no tenir cap correu que sigui Ham i que el consideri com Spam. Aquest par√†metre se'l pot considerar m√©s influent que el valor de k, ja que el valor de phi est√† directament lligat al nombre de falsos positius i de falsos negatius. En canvi el valor de k representa un coeficient molt baix a aplicar a totes les paraules.

Veiem els seg√ºents diagrames de dispersi√≥ donada una mostra de 500 punts sobre el total de les execucions.

```{r phi dispersion diagram}
m <- v[sample(nrow(v), size = 500), ]

par(mfrow=c(2,2))
plot(m$phi, m$tcr, main="PHI vs Total Cost Ratio", 
   xlab="phi", ylab="Total Cost Ratio", pch=19)

plot(m$phi, m$accuracy, main="PHI VS Accuracy", 
   xlab="phi", ylab="Accuracy", pch=19)

plot(m$phi, m$fp, main="PHI VS False positives", 
   xlab="phi", ylab="False Positives", pch=19)

plot(m$phi, m$fn, main="PHI VS False negatives", 
   xlab="phi", ylab="False negatives", pch=19)
par(mfrow=c(1,1))

```

En l'anterior grid podem veure diferents comparacions del comportament de la variable phi sobre una mostra de 500 elements dins del conjunt total de les execucions. Dels gr√†fics anteriors podem extreure certes conclusions a vista, tenint en compte que durant les execucions no s'ha fixat en cap moment ni un ordre de lectura de correus, ni un valor per k, ni un valor per phi i els correus per validar eren seleccionats aleat√≤riament. De totes maneres disposem d'un n√∫mero molt elevat i amb molta varietat de resultats.

- Es pot veure que la mitjana del tcr queda entre 1 i 6.
- Es pot veure com a m√©s valor de phi, m√©s disminueix el nombre de fp (lentament).
- Es pot veure com a m√©s valor de phi m√©s augmenta el nombre de fn (m√©s pronunciat).
- Es pot veure com l'accuracy √©s entre el 97 i 99 per√≤ que si el valor de phi augmenta llavors l'accuracy baixa 4 punts.

### K 

Quan apliquem el suavitzat hem de tenir en compte qu√® passa si donats el bag of words de ham i el de spam una paraula no existeix. En la nostra f√≥rmula aquest valor ens podria proporcionar multiplicacions per 0. Si una paraula no exist√≠s en algun dels conjunts, ens podria portar una classificaci√≥ err√≤nia.

Per tant la k estipula el valor que se li assigna a una paraula quan aquesta no √©s present. Aquest valor no pot ser 0, per√≤ pot ser proper a zero. Si fos zero, la probailitat calculada tamb√© seria zero i per tant no podriem classificar correctament. Tanmateix no t√© sentit aplicar un valor molt gran a la k, ja que si ho f√©ssim, aquest valor provocaria que les paraules que no existeixen fossin puntuades molt altes i es trauria valor de c√≤mput a les aparicions.

```{r K dispersion diagram }

par(mfrow=c(2,2))
plot(m$k, m$tcr, main="k vs Total Cost Ratio", 
   xlab="k", ylab="Total Cost Ratio", pch=19)

plot(m$k, m$accuracy, main="k VS Accuracy", 
   xlab="k", ylab="Accuracy", pch=19)

plot(m$k, m$fp, main="k VS False positives", 
   xlab="k", ylab="False Positives", pch=19)

plot(m$k, m$fn, main="k VS False negatives", 
   xlab="k", ylab="False negatives", pch=19)

par(mfrow=c(1,1))
```

Utilitzant el mateix sup√≤sit que en la variable phi observem doncs:

- Amb els valors de k pel tcr passa quelcom molt similar als valors de phi.
- Amb els valors de k m√©s petits l'accuracy augmenta, a mesura que es fa cr√©ixer el valor de k m√©s disminueix l'accuracy.
- Veiem que k no impacta molt en els falsos positius.
- Per altra banda veiem que t√© una relaci√≥ directa amb el comportament dels falsos negatius.
Limitarem els valors de k en un rang de (0 - 1].

### Conlusions conjuntes entre phi i k

No t√© sentit mirar les formes dels valors de phi i k de manera independent per qu√® s√≥n valors generats aleat√≤riament. El que s√≠ que t√© sentit √©s observar si les variables es poden descriure conjuntament amb el nombre de FP o FN i finalment si es poden comprovar mitjan√ßant el total cost ratio. La variable phi est√† directament lligada amb els valors FP i FN per definici√≥.

Si fem gr√†fics en 3D dels valors de k i phi en funci√≥ del tcr directament sobre la poblaci√≥ d'execucions que tenim podem veure coses interessants.

```{r scatter}

par(mfrow=c(1,2))
scatter3D(v$phi, v$k, v$tcr, phi = 0, theta=0, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5, xlab="PHI", ylab="K", zlab="TCR")
scatter3D(v$phi, v$k, v$tcr, phi = 0, theta=90, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5, xlab="PHI", ylab="K", zlab="TCR")

par(mfrow=c(1,2))
scatter3D(v$phi, v$k, v$tcr, phi = 0, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5)
scatter3D(v$phi, v$k, v$tcr, phi = 90, theta = 0.5, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5)
```

En els anteriors gr√†fics es pot distingir perfectament el rang d'actuaci√≥ dels valors m√©s alts per tcr. De la mateixa manera que s'ha extret les conclusions sobre una mostra, pensant que la mostra seria prou representativa, si observem sobre el total veiem que es confirmen les conclusions que hem anat exposant.

Donat el valor de k entre 0 i 1 i els valors de phi tamb√© entre 0.5 i 2.5 √©s per on es mou el tan buscat m√†xim global de la funci√≥ conjunta. Evidentment no hem formulat una hip√≤tesi concreta i no l'hem pogut verificar, ja que no hem ajustat el nostre model a cap mostra, per√≤ utilitzant el coeficient de correlaci√≥ de Pearson sobre els gr√†fics mostrats per phi i per k en les seccions anteriors, podem intuir el comportament de les variables.

No hem d'oblidar per√≤ que el valor del tcr s'ha tret directament de l'execuci√≥ amb les variables phi i k i per tant ens serveix per veure si hi ha algun patr√≥ pel qual la funci√≥ k o la funci√≥ phi de manera independent entre elles poden fer que creixi el valor del tcr. Tanmateix aix√≤ no ser√† possible pel fet que el valor del tcr s'extreu tant de la variable phi tant com de la variable k i **S'hauria de fixar o b√© la phi o b√© la k per poder extreure una conclusi√≥ sobre el tema**.


## QuË passa quan lemmatitzem.

Com hem citat abans, l'˙s de la llibreria Stanford Core NLP, ens permet distingir tipus de paraules, trobar l'arrel de les mateixes, etc. N'hem volgut fer un an‡lisi tan temporal com en efic‡cia, i aquestes sÛn les conclusion a les que hem pogut arribar:

Si ens basem en el temps, hem vist que el fet d'utilitzar el filtre amb la llibreria Stanford Core NLP, augmenta consedrablement, parlem de l'ordre de 100 vegades mÈs lent que si no utilitzem un filtratge de paraules.


TambÈ podem veure que parlant d'efic‡cia, l'utilitzaciÛ de la llibreria Stanford Core NLP, ens dÛna resultats amb valors d'accuracy inferiors al 90%. Podem veure un exemple d'execuciÛ amb 22.613 ,missatges:

```{r eval=FALSE}
---------------------------------------------------------
 Execution number  : 2
 Spam number???       : 10678.0
 Ham number        : 11935.0
 Unknown number???    : 2712.0
 PHI               : 2.239505399350125
 K                 : 0.3731320998425923
 Accuracy          : 86.09882005899705 %
 Tcr               : 3.517241369980792
---------------------------------------------------------
 Missatge HAM classificat correctament com a HAM: 1386.0
 Missatge HAM classificat com a SPAM : 0.0
 Missatge SPAM classificat correctament com spam : 949.0
 Missatge SPAM classificat com a HAM : 377.0
---------------------------------------------------------
```

Comparant amb un exemple d'execuciÛ sense filtre, que ens sol donar valors d'accuracy entre un 97% i 99%, un exemple d'execuciÛ seria:

```{r eval=FALSE}
---------------------------------------------------------
 Execution number  : 3
 Spam number       : 2989.0
 Ham number        : 3390.0
 Unknwon number    : 376.0
 PHI               : 1.917704909263815
 K                 : 0.5433680794849531
 Accuracy          : 98.67021276595744 %
 Total Cost Ratio  : 34.999993000001396
---------------------------------------------------------
 Missatge HAM classificat correctament com a HAM : 201.0
 Missatge HAM classificat com a SPAM : 0.0
 Missatge SPAM classificat correctament com spam : 170.0
 Missatge SPAM classificat com a HAM : 5.0
---------------------------------------------------------
```







## Refer√®ncies  

1. [R graphics](https://bl.ocks.org/patilv/raw/7360425/)
2. [Stanford lib](https://stanfordnlp.github.io/CoreNLP/)
