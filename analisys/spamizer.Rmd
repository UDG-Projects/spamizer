---
title: "Spamizer"
author: "Marc S√†nchez, Francesc Xavier Bullich, Gil Gass√≥"
date: "5/8/2019"
header-includes:
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead[CO,CE]{}
    - \fancyfoot[CO,CE]{}
    - \fancyfoot[LE,RO]{\thepage}
output:
  html_document:
    df_print: paged
  pdf_document:
    toc: yes
---

\newpage


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Carreguem les llibreries
library(scatterplot3d)
library(ggplot2)
library(colorspace)
library("plot3D")

# Carreguem les dades per a l'execuci√≥ del gr√†fic.
#resultsP1723K005 = read.csv("/home/marc/projects/main.java.spamizer/analisys/2000m-1000n-phi-1.7-2.3-k-0-0.5.csv")
```


```{r Functions}

# x √©s el nom del fitxer que volem carregar
loadFormattedData <- function(x){
  
  tmp = read.csv(x)
  names(tmp) <- c("id", "phi", "k", "tp", "tn", "fp", "fn", "nham", "nspam")
  
  #Calculem els tcr dels valors 
  # BASE :  (NSPAM) / (50 * NHAM + NSPAM) 
  base <- tmp$nspam / (50 * tmp$nham + tmp$nspam)
  # WERR: (50 * FP + FN)/(50 * NHAM + NSPAM) + 0.000001 -> per que no sigui 0
  werr <- (50 * tmp$fp + tmp$fn) / (50 * tmp$nham + tmp$nspam) + 0.000001
  # TCR : BASE / WERR
  tcr <- base/werr
  
  # Calculem l'accuracy
  accuracy <- (tmp$nspam + tmp$nham - tmp$fp - tmp$fn)/(tmp$nspam + tmp$nham) * 100
  
  # Generar una matriu que permeti representar els resultats en funci√≥ de k i phi
  values <- data.frame(accuracy, tcr)
  names(values) <- c("accuracy", "tcr")
  head(values)
  
  tmp <- cbind(tmp, values)
  
  # Ordenem els valors
  tmp <- tmp[order(-tmp$tcr), ]

   return(tmp)
}

```





# Naive Bayes

En aquest apartat s'especifica com s'adapta el m√®tode de naive bayes al filtratge de correu. 

DescripciÛ del codi amb el qual implementem el mËtode Naive Bayes.

Codi implementat:

```{r eval=FALSE}

 public boolean isSpam(MemDB memDB, Collection<String> message, double k, double phi)  {
        double spamProbability=0;
        double hamProbability=0;

        int hamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.HAM);
        int spamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.SPAM);

        List<String> words = new ArrayList<>(message);
        hamProbability = memDB.calculateProbability(words, TableEnumeration.Table.HAM,k,hamAlphabet);
        spamProbability = memDB.calculateProbability(words, TableEnumeration.Table.SPAM,k,spamAlphabet);

        double pTotalSpam = memDB.getMessageProbabylity(MemDB.Column.SPAM,k);
        double pTotalHam = memDB.getMessageProbabylity(MemDB.Column.HAM,k);

        //Tenim la probatilitat sumada de cada una de les paraules del missatge en forma de logaritme
        //sumem les probatilitats de que els missatges siguin spam o ham en forma de logaritme
        hamProbability += pTotalHam;
        spamProbability += pTotalSpam;

        //comparem les probabilitats obtingudes aplicant el parametre phi.
        return (spamProbability) > ((hamProbability)+ Math.log(phi));


    }
```

DescripciÛ pas a pas de les variables i funcions implementades.

Primer de tot el que fem Ès declarar dues variables que ens servir‡n per guardar tan la suma de probabilitats de cada paraula de que sigui spam o ham.

```{r eval=FALSE}
  double spamProbability=0;
  double hamProbability=0;
```

AquÌ el que fem Ès declarar dos enters que ens guarden el total de paraules que tenim registrades en la base de dades en memÚria com a spam i com a ham.

```{r eval=FALSE}
  int hamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.HAM);
  int spamAlphabet = memDB.getCountAlphabet(TableEnumeration.Table.SPAM);
```

Assignem els valors a les probabilitats de ham i spam. Sumem la probabilitat de cadascuna de les paraules del missatge de que siguin ham o spam.

```{r eval=FALSE}
  List<String> words = new ArrayList<>(message);
  hamProbability = memDB.calculateProbability(words, TableEnumeration.Table.HAM,k,hamAlphabet);
  spamProbability = memDB.calculateProbability(words, TableEnumeration.Table.SPAM,k,spamAlphabet);
```

Declarem dos variables que contindran els valors de la probabilitat total de que un missatge sigui spam o sigui ham.

```{r eval=FALSE}
  double pTotalSpam = memDB.getMessageProbabylity(MemDB.Column.SPAM,k);
  double pTotalHam = memDB.getMessageProbabylity(MemDB.Column.HAM,k);
```

Tan la suma de probabilitats de cada paraula del missatge com la probabilitat del missatge de ser spam o ham, est‡n logarimitzades, i per tant el que fem al final Ès sumar aquestes dades.

```{r eval=FALSE}
//Tenim la probatilitat sumada de cada una de les paraules del missatge en forma de logaritme
//sumem les probatilitats de que els missatges siguin spam o ham en forma de logaritme
  hamProbability += pTotalHam;
  spamProbability += pTotalSpam;
```

Finalment apliquem la fÛrmula amb phi quen ens permet donar import‡ncia al fet de  no classificar missatges Ham com a Spam, per tant com que volem estar segurs d'aixÚ fem el seg¸ent:
mirem que per classificar un missatge com a Spam, la probabilitat de ser spam ha de ser mÈs gran que phi vegades la probabilitat de que sigui ham.

```{r eval=FALSE}
(spamProbability) > ((hamProbability)+ Math.log(phi));
```



## Assumpcions.

El m√®tode de Naive Bayes assumeix que les caracter√≠stiques dels elements que analitza s√≥n independents entre si.

En el cas de processament de textos assumeix que cada una de les paraules d'un mateix bloc s√≥n independents de la resta.
Aix√≤ √≤bviament no √©s cert. Les frases es construeixen a partir d'una gram√†tica i tenen una sem√†ntica que relaciona cada una de les paraules que cont√© amb les altres. Per tant el fet de trobar X paraula al costat de Y √©s degut a una depend√®ncia entre elles.

Si consider√©ssim les depend√®ncies entre els elements, segurament nom√©s podr√≠em classificar exemples id√®ntics als que ja tenim classificats, per tant seria totalment in√∫til.

D'altra banda si considerem que les caracter√≠stiques s√≥n independents fa que puguem comptabilitzar m√©s cops elements que de forma conjunta (depenent) nom√©s comptabilitzar√≠em 1 sol cop.

En l'exemple dels correus:

- Si tenim en compte que les paraules d'una frase s√≥n depenents, trobar 1 frase que nom√©s surti a ham ens incrementa la probabilitat que el missatge sigui ham
- Si pel contrari assumim la independ√®ncia entre paraules. Comptabilitzarem cada una de les paraules de la frase, incrementant la probabilitat que sigui ham (aqu√≠ es pot veure la ingenu√Øtat del m√®tode).

## Punts forts i febles del m√®tode de Naive Bayes.

Punts forts:

- L'algoritme √©s prou f√†cil de construir i d'entendre.
- √âs un algoritme prou r√†pid i d√≥na prou bons resultats.
- Es pot entrenar amb un conjunt relativament petit d'exemples.
- En els casos que es compleixi l'assumpci√≥ d'independ√®ncia el m√®tode funciona millor.

Punts febles:

- L'assumpci√≥ d'independ√®ncia dels exemples pot fer que la classificaci√≥ no sigui correcte si no t√© una bona base d'exemples (ben diferenciats)
- El conjunt d'exemples ben diferenciat √©s dif√≠cil de trobar fora del m√≥n acad√®mic.
- Les caracter√≠stiques que no surtin al conjunt d'entrenament no es poden classificar correctament, ja que la probabilitat que assigna el m√®tode √©s 0.
- Si s'entrena malament la m√†quina, la m√†quina acaba enganyant. 
- Si hi ha molta difer√®ncia en nombre d'elements entre els diferents bag of words podem trobar inconsist√®ncies en els resultats.


# Applicaci√≥.

S'ha preparat el programa per que sigui una instrucci√≥ en java i per que el seu us sigui mitjan√ßant un java -jar.

Consulteu el [github del projecte](https://github.com/UDG-Projects/spamizer/).

## Tecnologies escollides.

L'aplicaci√≥ est√† feta en java en un format de comanda c. Per veure com s'executa l'aplicaci√≥ es pot consultar l'apartat manual de l'aplicaci√≥. La idea √©s generar un paquet jar i que rebi par√†metres.

S'han aplicat patrons de disseny de software tals com el patr√≥ strategy i el patr√≥ singleton. El patr√≥ strategy s'aplica en general a totes les possibles operacions que poden ser canviades en temps d'execuci√≥ mentre que el patr√≥ singleton s'aplica als accessos a les bases de dades.

L'aplicaci√≥ cont√© 2 bases de dades on es desa la informaci√≥ relativa al filtre. Una base de dades en mem√≤ria i una base de dades desada en local en un o diversos fitxers.

A causa del nombre de dades que es processen a casa execuci√≥ s'han replantejat les tecnologies escollides.

### Versi√≥ 1 

La primera versi√≥ de l'aplicaci√≥ i despr√©s de consultar diferents projectes relacionats amb el machine learning es va plantejar mitjan√ßant bases de dades SQL, concretament una base de dades feta amb HSQLDB en mem√≤ria i una base de dades tamb√© HSQLSB desada en un fitxer.

### Versi√≥ 2

Per culpa de la gran quantitat de dades que s'havia de processar i localitzant un coll d'ampolla en les operacions de logarimitzar que s'havien de fer sobre les dades extretes dins de les mateixes sent√®ncies SQL, s'ha implementat una segona versi√≥ mitjan√ßant hashmaps i mitjan√ßant fitxers .csv (Comma separated values).

La versi√≥ 2 corregeix la lentitud de l'acc√©s a les dades. Utilitza un mapa clau valor per les aparicions de les paraules de ham i un mapa clau valor per les aparicions de les paraules d'spam. Aix√≠ mateix els valors del total de missatges de ham i spam s√≥n comptadors i l'alphabet es representa amb un Set, √©s a dir, amb un conjunt de paraules.

## Manual de l'aplicaci√≥.

L'aplicaci√≥ √©s un programa en java executable amb la instrucci√≥ java -jar. El seu manual es llista a continuaci√≥ :

```{r eval=FALSE}

usage: main/java/spamizer
 -c <arg>   Usage : -c <spamDir> <hamDir> [-n <int>]
            Receives 2 parameters, A directory with spam mails and a
            directory with ham mails. A calculation for values phi and k
            will be done using a selection for the mails set. By default
            the selection will be random based on k-fold cross-validation
            and the heuristic method used to calculate phi and k values
            will be random
 -d         Flag that indicates that data must be loaded from local
            database, this database is allocated inside project dir named
            db made by csv files
 -h         Set training mails as ham, adding this argument -s must not be
            present
 -l         Uses Stanford core lib as lemmatizer for all, training and
            validation.
 -n <arg>   The number of iterations for -c mode execution.
 -o         Uses a ordered method to select and insert mails, using this
            option you can insert same mails ordre for all
            executions.Custom K-fold cross-validation by default.
 -p         Set the persistance of the memory database to a local database
 -s         Set training mails as spam, adding this argument -h must not
            be present
 -t <arg>   Directories where training mails in txt are stored, this or
            database argument must be present you can set a maximum of 2
            directories in this several order : -t <spamDir> <hamDir>. If
            only one dir is set the parameter -h or -s must be included
 -v <arg>   Directory where validation mails in txt are stored. This
            procedure will validate mail inside validationDir with
            database loaded by default or stored inside memory. [-h | -s]
            -v <validationDir> .

```


# Implementaci√≥ i exemples d'execuci√≥.

En aquest apartat s'expliquen els blocs amb qu√® s'ha dividit la part d'enginyeria del software aplicada a aquesta pr√†ctica, en concret els seg√ºents apartats mostren els patrons strategy.

## Lectura de fitxers. 

La interf√≠cie reader proporciona l'obligaci√≥ d'implementar el m√®tode que permet llegir i extreure textos d'una font de dades.

De la mateixa manera s'ha generat el DirectoryMailReader que implementa la interf√≠cie Reader i que √©s la classe que gestiona l'acc√©s a un directori en concret per extreure'n un llistat de correus.

## M√®tode de selecci√≥.

La interf√≠cie Selector √©s la que s'utilitza per separar el conjunt d'entrenament i de validaci√≥. Al ser una interf√≠cie, permet canviar el m√®tode de selecci√≥ en temps d'execuci√≥ i fent f√†cil la incorporaci√≥ de nous m√®todes de selecci√≥.

Aquest m√®tode entraria nom√©s a l'apartat -c de les execucions. Donades dues col¬∑leccions de correus √©s capa√ß d'extreure un subconjunt per spam i un subconjunt per ham deixant un tercer subconjunt com a correus per validar. S√≥n objectes correu i per tant, com a objecte correu, ja s'incorpora un camp boole√† que estipula si el correu √©s spam o ham. Aquest boole√†  s'utilitza al final de la validaci√≥ per comptabilitzar el nombre de correus classificats com a tp, fp, tn i fn.

### Adaptaci√≥ del m√®tode K-fold cross-validation.

S'utiltiza aquest m√®tode de selecci√≥ per defecte. Si no se li especifica la opci√≥ -o utilitza aquest. 

El m√®tode k-fold cross-validation aplica una divisi√≥ del total d'objectes de la poblaci√≥ en n parts. Donada aquesta divisi√≥ el mateix m√®tode va rotant, entrenant la BD amb n-1 parts i posteriorment aplica el m√®tode de validaci√≥ per la part que no s'ha fet servir per entrenar.

En el nostre cas tot i anomenar-lo k-fold cross-validation, **sabem que no ho √©s**, l'anomenem aix√≠ per qu√® ens vam basar en ell per definir el nostre m√®tode de selecci√≥.

Aquest consisteix en discriminar de la lectura un percentatge de correus (en el nostre cas entre el 5% i el 15% generat aleat√≤riament) del total de cada directori i posar-lo en una altra col¬∑lecci√≥ anomenada unknown. Aquesta col¬∑lecci√≥ ser√† utilitzada per a la validaci√≥ mentre que la resta s'utilitzen per training. Val a dir que la selecci√≥ es fa mitjan√ßant la generaci√≥ d'un nombre aleatori. Si el nombre √©s inferior al % generat el classifiquem com a unknown, en canvi si √©s superior o igual el classifiquem com spam o ham en funci√≥ del directori que s'estigui processant.

### Fixed Selection

La selecci√≥ fixada ha sigut implementada per a poder calcular m√©s acotadament els valors de phi i k. La selecci√≥ fixada sempre processa els mateixos correus amb el mateix ordre i discrimina els mateixos. D'aquesta manera podem generar execucions id√®ntiques amb valors diferents de les constants phi i k. Ens √©s molt √∫til per estudiar el seu comportament.

Per utiltizar aquesta opci√≥ de selecci√≥ es fa servir el par√†metre -o. 

```{r eval=FALSE}
java -jar spamizer.jar -o -n 1 -c
  "/home/marc/Escriptori/test/all/SPAM_TRAINING" 
  "/home/marc/Escriptori/test/all/HAM_TRAINING"
```

D'aquesta manera s'ordenaran els correus mitjan√ßant el nom del fitxer i es podran repetir les insercions, serveix per poder fixar els par√†metres de phi i k i veure com responen. 

## Filtre i abstracci√≥ del filtratge.

La interf√≠cie Filter permet generalitzar el filtratge de text procedent de cada correu electr√≤nic. Fent que es pugui canviar de filtre en temps d'execuci√≥. Tamb√© millora l'escalabilitat permetent que se'n puguin afegir de nous nom√©s implementant aquesta interf√≠cie.

### Stanford Core NLP.

La gent de Stanford ens proporciona una gran llibreria per al processament de textos. Veure la refer√®ncia [2]. La llibreria s'anomena Stanford Core NLP lib. Dins d'ella s'implementa un m√®tode de "tokenitzaci√≥", √©s a dir generaci√≥ de tokens per paraules que permeten estructurar el text i realitzar diferents comprovacions, com ara:

- Saber la categoria gramatical de la paraula (Nom, verb, determinant...)
- Posicionament de les paraules dins de par√†grafs, frases, expressions...
- Permet la **Lematitzaci√≥ de les paraules**, √©s a dir cercar l'arrel d'aquestes.
- An√†lisi de sentiments de les expressions dient si una frase √©s positiva, negativa ...
- Extreure subjecte, verb i predicats...

Entre altres.

Ens hauria agradat explotar m√©s aquesta llibreria per√≤ el temps per a la realitzaci√≥ de la pr√†ctica i el seu mateix objectiu ens allunyava de la possibilitat d'estudiar-la m√©s a fons, concretament el nostre filtre basat en StanfordCoreNLP realitza una discriminaci√≥ de totes les paraules que no s√≥n noms, verbs, adjectius, adverbis i lematitza tot el que li passen.

M√©s endavant hi ha conclusions sobre l'√∫s de la mateixa llibreria.

Per utilitzar el filtre lematitzador d'stanford s'ha d'especificar a la instrucci√≥ mitjan√ßant el par√†metre "-l".

```{r eval=FALSE}
java -jar spamizer.jar -l -n 1 -c 
  "/home/marc/Escriptori/test/all/SPAM_TRAINING" 
  "/home/marc/Escriptori/test/all/HAM_TRAINING"
```

### Custom Filter.

√âs el filtre utilitzat per defecte, si no se li especifica la opci√≥ -l fa servir aquest.

Aquest filtre simplement deixa passar tot el que se li d√≥na sempre que cada paraula compleixi amb el seu invariant sem√†ntic, √©s a dir, que tingui algun car√†cter. Extreu tamb√© les paraules "Subject:", "cc", "from" i "to", que tot i que en els correus de prova no hi s√≥n, en altres paquets de correus s√≠ que pot ser que ens els trobem. Tamb√© filtra els salt de l√≠nia i retorn de carro. 

## Entrenament. 

S'implementa a la classe Trainer. 

L'entrenament es pot efectuar de dues maneres, mitjan√ßant la instrucci√≥ amb el par√®metre -t o b√© amb la intrucci√≥ i el par√†metre -c que realitza un entrenament per cada iteraci√≥. M√©s endavant es parla de la fase compute que engloba l'entrenament i la validaci√≥. 

A la fase d'entrenament s'emplenen els bag of words i es realitza el comptatge en mem√≤ria de les paraules que s'han inserit tant per spam com per ham. Per realitzar una fase d'entrenament i desar l'entrenament per posteriors execucions es pot fer mitjan√ßant la seg√ºent combinaci√≥. 

```{r eval=FALSE}
java -jar spamizer.jar -p -t 
  "/home/marc/Escriptori/test/all/SPAM_TRAINING" 
  "/home/marc/Escriptori/test/all/HAM_TRAINING"
```

La opci√≥ -p serveix com a opci√≥ persist. Llegir√† la base de dades local que tinguem emplenada amb les execucions anteriors i far√† un merge amb l'entrenament que tingui realitzat en mem√≤ria. En cas que no hi hagi una base de dades local la generar√† amb fitxers csv. 

El par√†metre -t estipula que s'est√† entrenant i tal i com diu el manual de l'aplicaci√≥ l'ordre dels directoris importa, sempre va primer el directori spam. 

## Validaci√≥.

S'implementa a la classe Validator. 

La classe validator hereda directament de Trainer, per tant un validador tamb√© ens pot servir per entrenar, s'ha especificat aix√≠ per aconseguir alleugerir el codi i per que les fases puguin ser m√©s modulars. 

Aquesta fase estipula l'√∫s del m√®tode NaiveBayes per validar si un correu √©s spam o ham. mitjan√ßant uns contadors sap veure el nombre de True positive, true negative, false positive i false negative resultat de l'avaluaci√≥ dels diferents correus i actualitza la variable global Results amb les dades de la validaci√≥. Per tant aquesta classe a part de fer el training fa el proc√©s de validar els correus llen√ßant el m√®tode Naive Bayes 

## Compute.

Durant la la fase experimental al desenvolupament ens vam adonar que necessit√†vem una manera √≤ptima de poder generar valors de k i de phi. Llavors vam inventar aquest m√®tode per tractar k i phi com a variables dins d'una execuci√≥ del nostre filtre. 

El que permet √©s assignar-li, mitjan√ßant el par√†metre -n un nombre d'execucions, els resultats de les quals es desen a un fitxer csv anomenat results.csv. Aquests son els fitxers que s'utilitzen m√©s endavant per a l'evaluaci√≥ de la fase experimental. 

Mitjan√ßant el par√†metre -c proporcionant valors per el par√†metre -n i directoris d'spam i de ham, el nostre filtre de correu far√† -n iteracions amb -n valors per k i -n valors per phi. Els valors de k i phi seran generats amb k entre 0.0000001 i 1 i phi entre 1 i 5 de manera aleat√≤ria.

Un exemple d'execuci√≥ seria : 

```{r eval=FALSE}
java -jar spamizer.jar -n 10 -c 
  "/home/marc/Escriptori/test/all/SPAM_TRAINING" 
  "/home/marc/Escriptori/test/all/HAM_TRAINING"
```

Que realitza 10 iteracions amb 10 filtratges diferents i 10 execucions totalment diferents. 

Es pot customitzar l'execuci√≥ del par√†metre -c mitjan√ßant els par√†metres -o i -l. El par√†metre -o estipula si l'entrenament i la separaci√≥ dels correus per validar ha de tenir un ordre en concret, en cas que -o aparegui els fitxers s'ordenaran de manera alfab√®tica pemetent generar la mateixa execuci√≥ sempre amb diferents valors de k i phi. Molt √∫til per veure com oscil¬∑len aquests valors. 

El par√†metre -l permet lematitzar la inserci√≥ de les paraules i la lectura dels correus a validar mitjan√ßant la llibreria StanfordCoreNLP [2]. 

Per defecte s'utilitza una selecci√≥ que n'anomenem Custom K-Fold cross-Validation (ja que no √©s un k-fold per√≥ la idea va sorgir d'all√†) i la informaci√≥ es filtra amb el filtre Custom, descrit anteriorment.


```{r eval=FALSE}
java -jar spamizer.jar -o -l -n 10 -c 
  "/home/marc/Escriptori/test/all/SPAM_TRAINING" 
  "/home/marc/Escriptori/test/all/HAM_TRAINING"
```

# Fase Experimental.

En aquesta fase es presenten una s√®rie de gr√†fics i una an√†lisi (no confirmat) sobre totes les execucions que s'han anat realitzant.

## C√†lcul del TCR (Total Cost Ratio)

Amb el Total cost ratio podem extreure un valor que pondera amb m√©s for√ßa el valor de les aparicions dels falsos positius. El que es busca amb el TCR √©s el valor m√†xim possible. Per fer-ho hem realitzat diverses execucions i hem preparat una s√®rie de conclusions per intentar esbrinar les funcions phi i k que millor s'ajusten al nostre problema mitjan√ßant el c√†lcul del TCR.

### Veiem com es pot generar la columna TCR

```{r tcr}
results = read.csv("./20000m-500n-SF.csv")
#Calculem els tcr dels valors 
# BASE :  (NSPAM) / (50 * NHAM + NSPAM) 
base <- results$NSPAM / (50 * results$NHAM + results$NSPAM)
# WERR: (50 * FP + FN)/(50 * NHAM + NSPAM) + 0.000001 -> per que no sigui 0
werr <- (50 * results$FP + results$FN) / (50 * results$NHAM + results$NSPAM) + 0.000001
# TCR : BASE / WERR
tcr <- base/werr

# Generar una matriu que permeti representar els resultats en funci√≥ de k i phi
values <- data.frame(results$PHI, results$K, tcr)
names(values) <- c("phi", "k", "tcr")
head(values)

# Ordenem els valors
values <- values[order(-values$tcr), ]
head(values,20)

```

## An√†lisi de la PHI i la K.

Carreguem les diferents simulacions en un dataframe per poder processar les dades. Utilitzem la funci√≥ loadFormattedData declarada a l'apartat de funcions del document. Aquesta funci√≥ ens afegeix les columnes calculades per l'accuracy i el TCR.

```{r Loading data}
b1 = loadFormattedData("./m20000-n9500-SF-P-16-k-03.csv")
b2 = loadFormattedData("./m20000-n10000-P-15-K-03.csv")
b3 = loadFormattedData("./20000m-500n-SF.csv")
b4 = loadFormattedData("./2000m-1000n-phi-1.7-2.3-k-0-0.5.csv")

v <- rbind(b1, b2, b3, b4)
v <- v[order(-v$tcr), ]
head(v)
```

### PHI

El valor m√≠nim que t√© sentit assignar-li a phi √©s 1 i el m√†xim el podr√≠em limitar a 5 com a molt o incl√∫s a 6 si el que volem √©s no tenir cap correu que sigui Ham i que el consideri com Spam. Aquest par√†metre se'l pot considerar m√©s influent que el valor de k, ja que el valor de phi est√† directament lligat al nombre de falsos positius i de falsos negatius. En canvi el valor de k representa un coeficient molt baix a aplicar a totes les paraules.

Veiem els seg√ºents diagrames de dispersi√≥ donada una mostra de 500 punts sobre el total de les execucions.

```{r phi dispersion diagram}
m <- v[sample(nrow(v), size = 500), ]

par(mfrow=c(2,2))
plot(m$phi, m$tcr, main="PHI vs Total Cost Ratio", 
   xlab="phi", ylab="Total Cost Ratio", pch=19)

plot(m$phi, m$accuracy, main="PHI VS Accuracy", 
   xlab="phi", ylab="Accuracy", pch=19)

plot(m$phi, m$fp, main="PHI VS False positives", 
   xlab="phi", ylab="False Positives", pch=19)

plot(m$phi, m$fn, main="PHI VS False negatives", 
   xlab="phi", ylab="False negatives", pch=19)
par(mfrow=c(1,1))

```

En l'anterior grid podem veure diferents comparacions del comportament de la variable phi sobre una mostra de 500 elements dins del conjunt total de les execucions. Dels gr√†fics anteriors podem extreure certes conclusions a vista, tenint en compte que durant les execucions no s'ha fixat en cap moment ni un ordre de lectura de correus, ni un valor per k, ni un valor per phi i els correus per validar eren seleccionats aleat√≤riament. De totes maneres disposem d'un n√∫mero molt elevat i amb molta varietat de resultats.

- Es pot veure que la mitjana del tcr queda entre 1 i 6.
- Es pot veure com a m√©s valor de phi, m√©s disminueix el nombre de fp (lentament).
- Es pot veure com a m√©s valor de phi m√©s augmenta el nombre de fn (m√©s pronunciat).
- Es pot veure com l'accuracy √©s entre el 97 i 99 per√≤ que si el valor de phi augmenta llavors l'accuracy baixa 4 punts.

### K 

Quan apliquem el suavitzat hem de tenir en compte qu√® passa si donats el bag of words de ham i el de spam una paraula no existeix. En la nostra f√≥rmula aquest valor ens podria proporcionar multiplicacions per 0. Si una paraula no exist√≠s en algun dels conjunts, ens podria portar una classificaci√≥ err√≤nia.

Per tant la k estipula el valor que se li assigna a una paraula quan aquesta no √©s present. Aquest valor no pot ser 0, per√≤ pot ser proper a zero. Si fos zero, la probailitat calculada tamb√© seria zero i per tant no podriem classificar correctament. Tanmateix no t√© sentit aplicar un valor molt gran a la k, ja que si ho f√©ssim, aquest valor provocaria que les paraules que no existeixen fossin puntuades molt altes i es trauria valor de c√≤mput a les aparicions.

```{r K dispersion diagram }

par(mfrow=c(2,2))
plot(m$k, m$tcr, main="k vs Total Cost Ratio", 
   xlab="k", ylab="Total Cost Ratio", pch=19)

plot(m$k, m$accuracy, main="k VS Accuracy", 
   xlab="k", ylab="Accuracy", pch=19)

plot(m$k, m$fp, main="k VS False positives", 
   xlab="k", ylab="False Positives", pch=19)

plot(m$k, m$fn, main="k VS False negatives", 
   xlab="k", ylab="False negatives", pch=19)

par(mfrow=c(1,1))
```

Utilitzant el mateix sup√≤sit que en la variable phi observem doncs:

- Amb els valors de k pel tcr passa quelcom molt similar als valors de phi.
- Amb els valors de k m√©s petits l'accuracy augmenta, a mesura que es fa cr√©ixer el valor de k m√©s disminueix l'accuracy.
- Veiem que k no impacta molt en els falsos positius.
- Per altra banda veiem que t√© una relaci√≥ directa amb el comportament dels falsos negatius.
Limitarem els valors de k en un rang de (0 - 1].

### Conlusions conjuntes entre phi i k

No t√© sentit mirar les formes dels valors de phi i k de manera independent per qu√® s√≥n valors generats aleat√≤riament. El que s√≠ que t√© sentit √©s observar si les variables es poden descriure conjuntament amb el nombre de FP o FN i finalment si es poden comprovar mitjan√ßant el total cost ratio. La variable phi est√† directament lligada amb els valors FP i FN per definici√≥.

Si fem gr√†fics en 3D dels valors de k i phi en funci√≥ del tcr directament sobre la poblaci√≥ d'execucions que tenim podem veure coses interessants.

```{r scatter}

par(mfrow=c(1,2))
scatter3D(v$phi, v$k, v$tcr, phi = 0, theta=0, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5, xlab="PHI", ylab="K", zlab="TCR")
scatter3D(v$phi, v$k, v$tcr, phi = 0, theta=90, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5, xlab="PHI", ylab="K", zlab="TCR")

par(mfrow=c(1,2))
scatter3D(v$phi, v$k, v$tcr, phi = 0, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5)
scatter3D(v$phi, v$k, v$tcr, phi = 90, theta = 0.5, bty = "g",  type = "h", ticktype = "detailed", pch = 19, cex = 0.5)
```

En els anteriors gr√†fics es pot distingir perfectament el rang d'actuaci√≥ dels valors m√©s alts per tcr. De la mateixa manera que s'ha extret les conclusions sobre una mostra, pensant que la mostra seria prou representativa, si observem sobre el total veiem que es confirmen les conclusions que hem anat exposant.

Donat el valor de k entre 0 i 1 i els valors de phi tamb√© entre 0.5 i 2.5 √©s per on es mou el tan buscat m√†xim global de la funci√≥ conjunta. Evidentment no hem formulat una hip√≤tesi concreta i no l'hem pogut verificar, ja que no hem ajustat el nostre model a cap mostra, per√≤ utilitzant el coeficient de correlaci√≥ de Pearson sobre els gr√†fics mostrats per phi i per k en les seccions anteriors, podem intuir el comportament de les variables.

No hem d'oblidar per√≤ que el valor del tcr s'ha tret directament de l'execuci√≥ amb les variables phi i k i per tant ens serveix per veure si hi ha algun patr√≥ pel qual la funci√≥ k o la funci√≥ phi de manera independent entre elles poden fer que creixi el valor del tcr. Tanmateix aix√≤ no ser√† possible pel fet que el valor del tcr s'extreu tant de la variable phi tant com de la variable k i **S'hauria de fixar o b√© la phi o b√© la k per poder extreure una conclusi√≥ sobre el tema**.

## QuË passa quan lemmatitzem.

Com hem citat abans, l'˙s de la llibreria Stanford Core NLP, ens permet distingir tipus de paraules, trobar l'arrel de les mateixes, etc. N'hem volgut fer un an‡lisi tan temporal com en efic‡cia, i aquestes sÛn les conclusion a les que hem pogut arribar:

Si ens basem en el temps, hem vist que el fet d'utilitzar el filtre amb la llibreria Stanford Core NLP, augmenta consedrablement, parlem de l'ordre de 100 vegades mÈs lent que si no utilitzem un filtratge de paraules.


TambÈ podem veure que parlant d'efic‡cia, l'utilitzaciÛ de la llibreria Stanford Core NLP, ens dÛna resultats amb valors d'accuracy inferiors al 90%. Podem veure un exemple d'execuciÛ amb 22.613 ,missatges:

```{r eval=FALSE}
---------------------------------------------------------
 Execution number  : 2
 Spam number???       : 10678.0
 Ham number        : 11935.0
 Unknown number???    : 2712.0
 PHI               : 2.239505399350125
 K                 : 0.3731320998425923
 Accuracy          : 86.09882005899705 %
 Tcr               : 3.517241369980792
---------------------------------------------------------
 Missatge HAM classificat correctament com a HAM: 1386.0
 Missatge HAM classificat com a SPAM : 0.0
 Missatge SPAM classificat correctament com spam : 949.0
 Missatge SPAM classificat com a HAM : 377.0
---------------------------------------------------------
```

Comparant amb un exemple d'execuciÛ sense filtre, que ens sol donar valors d'accuracy entre un 97% i 99%, un exemple d'execuciÛ seria:

```{r eval=FALSE}
---------------------------------------------------------
 Execution number  : 3
 Spam number       : 2989.0
 Ham number        : 3390.0
 Unknwon number    : 376.0
 PHI               : 1.917704909263815
 K                 : 0.5433680794849531
 Accuracy          : 98.67021276595744 %
 Total Cost Ratio  : 34.999993000001396
---------------------------------------------------------
 Missatge HAM classificat correctament com a HAM : 201.0
 Missatge HAM classificat com a SPAM : 0.0
 Missatge SPAM classificat correctament com spam : 170.0
 Missatge SPAM classificat com a HAM : 5.0
---------------------------------------------------------
```


## Comparativa amb un altre programa

Analitzats els nostres resultats, passem a veure una comparativa amb un altre filtre de spam. Utilitzarem Mallet seguint les indicacions de la pr√†ctica.


MALLET [3] √©s un paquet basat en Java per al processament estad√≠stic del llenguatge natural, classificaci√≥ de documents, agrupaci√≥, modelitzaci√≥ de temes, extracci√≥ d'informaci√≥ i altres aplicacions d'aprenentatge autom√†tic al text.

Entre d'altres, inclou m√©todes com Na√Øve Bayes per a la classificaci√≥ de documents.

### Com funciona Mallet

Mallet t√© moltes modaltats per√≤ nom√©s ens centrarem en aquelles que inclouen el processament necessari per realitzar una validacio de filtre de spam (classificacio de documents).

De forma similar al nostre programa, mallet funciona en mode de comanda des d'un terminal. Hem d'indicar quins son els directoris on hi ha els documents a classificar, i despr√©s mitjan√ßant opcions parametritzades, indicarli quin ser√† el m√®tode de classificaci√≥ utilitzat.

Carregar els directoris:

```{r eval=FALSE}

bin\mallet import-dir --input "emailsENRON\SPAM" "emailsENRON\HAM" --output data.mallet

```

- Opci√≥ imput: Quan fem import-dir hem d'indicar quins son els directoris on hi ha els documents a carregar (s'en poden indcar v√†ris).
- Opcio output: Fitxer on es guardar√† el resultat de la carrega de dades (aquest fitxe ja conte els tokens processats)

Executar validaci√≥ amb Na√Øve Bayes:

```{r eval = FALSE}
bin\mallet train-classifier --input data.mallet --trainer NaiveBayes --training-portion 0.9 --num-trials 10
```

- Opci√≥ input: Indica quin es el fitxer d'entrada on hi ha les dades per el proces de classificaci√≥ (en aquest cas ha d'estar carregat i processat previament)
- Opci√≥ trainer: Indica quin tipus de validaci√≥ s'utilitzara (s'en pot indicar m√©s d'un)
- Opci√≥ training-portion: Indica quin percentatge de documents s'utilitzar√† d'entrenament i validaci√≥. En aquest cas la relaci√≥ √©s (90:10)
- Opci√≥ num-trials: Indica quantes iteracions de d'entrenament-validaci√≥ s'executaran.

Si mirem l'apartat d'implementaci√≥, podem comprovar que les dues aplicacions funcionen de forma similar, siguent mallet m√©s complet i amb alters funcionalitats que no entren en el context de la pr√†ctica.

Per exemple la noste opci√≥ d'entrenament -t amb persist√®ncia -p seria similar al import-dir --input --output.

El m√®tode de particionat es simialar el que tenim tamb√©. S'indica una proporcio de documents d'entrenament (0.9), la resta ser√† pel conjunt de validaci√≥. En el nostre cas, com s'ha comentat en l'apartat d'implementaci√≥, √©s un percentatge variable.
Mallet tamb√© permet la utilitzaci√≥ del m√®tode k-fold-cross-validation, en comptes del particionat aleatori.

```{r eval = FALSE}
bin\mallet train-classifier --input data.mallet --trainer NaiveBayes --cross-validation 10
```

### Resultats

Per que els resultats siguin similars, utilitzem el m√®tode de particionat aleatori per fer la comparaci√≥.

Aquests s√≥n alguns dels resultats obtinguts (No calcula el TCR, s'afageix manualment al final de cada resultat):

```{r eval = FALSE}
-------------------- Trial 1  --------------------

Trial 1 Training NaiveBayesTrainer with 17999 instances
Trial 1 Training NaiveBayesTrainer finished
Trial 1 Trainer NaiveBayesTrainer training data accuracy= 0.9869992777376521
Trial 1 Trainer NaiveBayesTrainer Test Data Confusion Matrix
Confusion Matrix, row=true, column=predicted  accuracy=0.98
   label   0   1  |total
  0 SPAM 981  30  |1011
  1  HAM  10 979  |989

Trial 1 Trainer NaiveBayesTrainer test data accuracy= 0.98
TCR: 1,907547

-------------------- Trial 2  --------------------

Trial 2 Training NaiveBayesTrainer with 17999 instances
Trial 2 Training NaiveBayesTrainer finished
Trial 2 Trainer NaiveBayesTrainer training data accuracy= 0.9872215123062392
Trial 2 Trainer NaiveBayesTrainer Test Data Confusion Matrix
Confusion Matrix, row=true, column=predicted  accuracy=0.981
   label   0   1  |total
  0 SPAM 966  32  |998
  1  HAM   6 996  |1002

Trial 2 Trainer NaiveBayesTrainer test data accuracy= 0.981
TCR: 3,006024
...

-------------------- Trial 6  --------------------

Trial 6 Training NaiveBayesTrainer with 17999 instances
Trial 6 Training NaiveBayesTrainer finished
Trial 6 Trainer NaiveBayesTrainer training data accuracy= 0.9866103672426246
Trial 6 Trainer NaiveBayesTrainer Test Data Confusion Matrix
Confusion Matrix, row=true, column=predicted  accuracy=0.9825
   label   0   1  |total
  0 SPAM 974  34  |1008
  1  HAM   1 991  |992

Trial 6 Trainer NaiveBayesTrainer test data accuracy= 0.9825
TCR: 12


```


Com es pot observar els resultats dels dos filtres son molt similars. Tots dos tenen una mitjana d'accracy del 98-99%.
Pel que fa al TCR veiem que tamb√© son for√ßa similars, tinguent en compte que nom√©s hem fet 10 iteracions. En el millor dels casos de 10 execucions ha tret 1 sol fals positiu.

Les notres millors execucions mostren un TCR de fins 57 amb accuracy del 99%, despr√®s de fer moltissimes execucions per afinar un valor de phi i k.
Mallet no mostra aquests valors per tant no podem comparar-los.


Si tenim en compte la difer√®ncia de nombre d'execucions i l'afinament dels par√†metres, comparant els dos programes podem dir que hem fet un bon classificador amb Na√Øve Bayes.


## Refer√®ncies  

1. [R graphics](https://bl.ocks.org/patilv/raw/7360425/)
2. [Stanford lib](https://stanfordnlp.github.io/CoreNLP/)
3. [Mallet](http://mallet.cs.umass.edu/index.php)

